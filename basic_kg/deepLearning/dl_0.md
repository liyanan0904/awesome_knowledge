# 深度学习相关
## 深度学习的实质与浅层学习的区别
1. 深度学习实质：多隐层+海量数据——>学习有用特征—–>提高分类或预测准确性；
2. 区别：
    - DL强调模型深度
    - DL突出特征学习的重要性：特征变换+非人工

## BP算法为什么不能适应于深度学习
BP为传统多层感知机的训练方法，<=5层
问题：
- 梯度越来越稀疏（梯度扩散<—-非凸目标函数）
- 局部最小
- 一般，有标签

NOTE：解决其中局部最小值的方法：（1）多组不同随机参数，取最好参数 （2）启发式优化算法：模拟退火 或 遗传 （3）随机梯度下降

## CNN卷基层和pooling层的作用
- 卷积层：特征提取
- 子采样层/池化层：缩减输入数据的规模

## DNN常用的激活函数有哪些，各有什么特点
1. sigmoid：易饱和（梯度消失），非0均值 
2. tanh，改进了sigmoid的第二个缺点，即它是0均值的 
3. ReLU，收敛快（不容易饱和），求梯度简单（没有指数计算，只需要阈值就可以），有稀疏特性。缺点是神经元容易坏死。




